# pytorch_lightning==2.2.5
seed_everything: 2
trainer:
  accelerator: gpu
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: 32
  logger: 
    class_path: pytorch_lightning.loggers.TensorBoardLogger
    init_args:
      save_dir: ./logs
      name: exp
      version: null
    class_path: pytorch_lightning.loggers.CometLogger
    init_args:
      api_key: FItcqtFxcX4Trzy5wPfDSiC49
      project_name: pytorch-lightning-template-for-beginners
      experiment_name: exp1
      workspace: mrbernie
      save_dir: ./comet_logs

  # callbacks:
  # - class_path: pytorch_lightning.callbacks.ModelCheckpoint
  #   init_args:
  #     monitor: valid/loss
  #     mode: min
  #     save_top_k: -1
  #     save_last: true
  #     save_weights_only: true
  #     filename: '{epoch}-{val/loss:.4f}'
  #     verbose: true
  #     dirpath: ckpt
  # - class_path: pytorch_lightning.callbacks.RichProgressBar
  #   init_args:
  #     refresh_rate: 1
  #     leave: false
  #     theme:
  #       description: green_yellow
  #       progress_bar: green1
  #       progress_bar_finished: green1
  #       progress_bar_pulse: '#6206E0'
  #       batch_progress: green_yellow
  #       time: grey82
  #       processing_speed: grey82
  #       metrics: grey82
  #     console_kwargs:
  #       force_terminal: true
  #       no_color: false
  #       width: 200
  fast_dev_run: false
  max_epochs: 100
  min_epochs: null
  max_steps: -1
  min_steps: null
  max_time: null
  limit_train_batches: null
  limit_val_batches: null
  limit_test_batches: null
  limit_predict_batches: null
  overfit_batches: 0.0
  val_check_interval: null
  check_val_every_n_epoch: 1
  num_sanity_val_steps: null
  log_every_n_steps: 10
  enable_checkpointing: true
  enable_progress_bar: true
  enable_model_summary: null
  accumulate_grad_batches: 1
  gradient_clip_val: null
  gradient_clip_algorithm: null
  deterministic: null
  benchmark: null
  inference_mode: true
  use_distributed_sampler: true
  profiler: null
  detect_anomaly: false
  barebones: false
  plugins: null
  sync_batchnorm: false
  reload_dataloaders_every_n_epochs: 0
  default_root_dir: null
model:
  arch:
    class_path: __main__.MyArch
    init_args:
      input_size: 8
      output_size: 2
  exp_name: exp
  compile: false
data:
  input_size:
  - 8
  - 64000
  num_workers: 5
  batch_size:
  - 2
  - 4
early_stopping:
  monitor: val/loss
  min_delta: 0.01
  patience: 10
  verbose: false
  mode: min
  strict: true
  check_finite: true
  stopping_threshold: null
  divergence_threshold: null
  check_on_train_epoch_end: null
  log_rank_zero_only: false
model_checkpoint:
  dirpath: null
  filename: epoch{epoch}_valid_loss{val/loss:.4f}
  monitor: val/loss
  verbose: false
  save_last: true
  save_top_k: 5
  save_weights_only: false
  mode: min
  auto_insert_metric_name: false
  every_n_train_steps: null
  train_time_interval: null
  every_n_epochs: 1
  save_on_train_epoch_end: null
  enable_version_counter: true
progress_bar:
  refresh_rate: 1
  leave: false
  theme:
    description: white
    progress_bar: '#6206E0'
    progress_bar_finished: '#6206E0'
    progress_bar_pulse: '#6206E0'
    batch_progress: white
    time: grey54
    processing_speed: grey70
    metrics: white
    metrics_text_delimiter: ' '
    metrics_format: .3f
  console_kwargs:
    force_terminal: true
    no_color: true
    width: 200
# learning_rate_monitor:
#   logging_interval: epoch
#   log_momentum: false
#   log_weight_decay: false
ckpt_path: null # ./ckpt
